```{r gvis3}
# GoogleMotionChart erstellen...
bubble <- gvisMotionChart(filter(select(d2_tbl4, head, date, logFreq, COLL.STR.LOGL, collex, collex2), logFreq > 0),
idvar = "head",
sizevar = "logFreq",
yvar="logFreq",
xvar="collex2",
timevar = "date")
# ... und mit dem Plot-Befehl aktivieren
plot(bubble)
```
Et voilà - wenn Sie es schaffen, den FlashPlayer zu aktivieren, können Sie jetzt ein wenig mit den Daten herumspielen.
Statt eines Schlussworts eher eine Zwischenbilanz: Ich hoffe, Sie konnten das eine oder andere aus diesem Tutorial lernen, auch wenn es noch work-in-progress ist und gerade diese dritte Seite noch etwas Feinschliff bedürfte. Ich hoffe, dass ich diesen Feinschliff bald ergänzen kann...
filter(select(d2_tbl4, head, date, logFreq, COLL.STR.LOGL, collex, collex2), logFreq > 0)
d2_tbl4
d2_tbl4$logFreq
d2_tbl4$LogFreq
d2_tbl4$logFreq
d2_tbl4$Freq_on_date
d2_tbl4$LogFreq
# Frequenz (per date) logarithmieren
d2_tbl4$logFreq <- log1p(d2_tbl4$Freq_on_date)
filter(select(d2_tbl4, head, date, LogFreq, COLL.STR.LOGL, collex, collex2), LogFreq > 0)
filter(select(d2_tbl4, head, date, LogFreq, COLL.STR.LOGL, collex, collex2), logFreq > 0)
filter(select(d2_tbl4, head, date, LogFreq, logFreq, COLL.STR.LOGL, collex, collex2), logFreq > 0)
# GoogleMotionChart erstellen...
bubble <- gvisMotionChart(filter(select(d2_tbl4, head, date, logFreq, COLL.STR.LOGL, collex, collex2), logFreq > 0),
idvar = "head",
sizevar = "logFreq",
yvar="logFreq",
xvar="collex2",
timevar = "date")
# ... und mit dem Plot-Befehl aktivieren
plot(bubble)
d2_tbl4$LogFreq
d2_tbl4$logFreq
# GoogleMotionChart erstellen...
bubble <- gvisMotionChart(filter(select(d2_tbl4, head, date, LogFreq, COLL.STR.LOGL, collex, collex2), LogFreq > 0),
idvar = "head",
sizevar = "LogFreq",
yvar="LogFreq",
xvar="collex2",
timevar = "date")
# ... und mit dem Plot-Befehl aktivieren
plot(bubble)
d2_tbl4$Freq_on_date
d2_tbl4$Freq
library(tidyverse)
library(googleVis)
library(lubridate)
library(collostructions)
d <- read_delim("Coronakomposita.txt", delim = "\t",
col_names = c("Freq", "word", "date"))
d
str(d)
# Fehltreffer reduzieren
d <- d[-which(sapply(1:nrow(d), function(i) nchar(d$word[i]))<=8),]
# Groß- und Kleinschreibung ignorieren
d$word <- tolower(d$word)
# Köpfe
d$head <- gsub("corona-?", "", d$word)
# Interpunktion löschen
d$head <- gsub("[[:punct:]]", "", d$head)
corona_tbl <- d %>% group_by(head) %>% summarise(
Freq = sum(Freq)
) %>% arrange(desc(Freq))
# einlesen
nouns <- read_delim("allnouns_dwds21.txt",
delim = "\t", quote="",
col_names = c("Freq_dwds21", "word"))
# alle in Kleinschreibung
nouns$word <- tolower(nouns$word)
# neu auszählen (um groß- und kleingeschriebene Varianten zu vereinen)
nouns <- nouns %>% group_by(word) %>% summarise(
Freq_dwds21 = sum(Freq_dwds21)
)
corona_tbl <- left_join(corona_tbl, nouns, by = c("head" = "word"))
corona_tbl <- replace_na(corona_tbl, list(Freq_dwds21 = 0))
corona_coll <- collex.dist(as.data.frame(corona_tbl))
head(corona_coll)
plot(corona_tbl$Freq, type = "b", ylab = "Absolute Frequenz")
plot(log(corona_tbl$Freq), type = "b", ylab = "Logarithmierte Frequenz")
# Log-Frequenz hinzufügen
corona_coll$LogFreq <- log(corona_coll$O.CXN1)
FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Morphologische Produktivität live: Ein Blick auf die Bestimmungsglieder
In diesem Abschnitt wollen wir uns nun einen anderen Weg anschauen, auf dem wir uns den Daten nähern können. Hierfür arbeiten wir mit R - falls Sie sich hier einarbeiten wollen, finden Sie online extrem viele gute Tutorials, und es gibt auch viele Einführungen in die Statistik speziell für Linguist*innen, die mit R arbeiten. Hier kann ich nicht in R einführen, versuche aber, das, was ich mache, so verständlich zu beschreiben, dass Sie zumindest das Konzept hinter dem, was ich mache, verstehen können.
Zunächst lade ich einige Zusatzpakete, die ich im Folgenden benutzen möchte. Sie enthalten Funktionen, die in R nicht standardmäßig enthalten sind. Wenn Sie die Pakete noch nicht installiert haben, müssen Sie siejedes einzelne zunächst mit `install.packages("Paketname")` installieren. Das gilt für diejenigen, die über das "Comprehensive R Architecture Network" (CRAN) verfügbar sind. Bei einem der Pakete, "collostructions", ist dies nicht der Fall, Sie finden es unter www.sfla.ch.
```{r preliminaries, message = FALSE}
library(tidyverse)
library(googleVis)
library(lubridate)
library(collostructions)
```
Zunächst lesen wir die Daten ein, werfen einen Blick auf die Struktur der Daten und schauen uns diese mit Hilfe des `str()`-Befehls genauer an.
```{r readdata}
d <- read_delim("Coronakomposita.txt", delim = "\t",
col_names = c("Freq", "word", "date"))
```
```{r head}
d
```
```{r str}
str(d)
```
Nun löschen wir alle Datenpunkte, in denen "Corona" nicht von mindestens zwei weiteren Zeichen gefolgt wird, um Fehltreffer wie *Corona-* zu tilgen. Dann konvertieren wir alle Daten in Kleinschreibung und fügen eine Spalte hinzu, die nur die Zweitglieder enthält (also alles, was auf *Corona-* folgt). Aus dieser Spalte löschen wir zusätzlich noch alle Interpunktionszeichen, um z.B. Fälle der Kompositaschreibung mit und ohne Bindestrich zu vereinheitlichen.
```{r datawrangling}
# Fehltreffer reduzieren
d <- d[-which(sapply(1:nrow(d), function(i) nchar(d$word[i]))<=8),]
# Groß- und Kleinschreibung ignorieren
d$word <- tolower(d$word)
# Köpfe
d$head <- gsub("corona-?", "", d$word)
# Interpunktion löschen
d$head <- gsub("[[:punct:]]", "", d$head)
```
Wir fassen die Daten nun mit der `summarise`-Funktion aus dem dplyr-Paket (Teil des "Tidyverse") zusammen, um die Gesamtfrequenzen jedes Bestimmungsglieds zu bekommen, und ordnen die Daten absteigend nach Frequenz. Das Ganze speichern wir in einen eigene Dataframe, den wir `corona_tbl` nennen.
```{r summary}
corona_tbl <- d %>% group_by(head) %>% summarise(
Freq = sum(Freq)
) %>% arrange(desc(Freq))
```
corona_tbl
# Anzahl der Types = Anzahl der Zeilen der eben genereierten Tabelle:
types <- nrow(corona_tbl)
# Anzahl der Tokens = Summe der Frequenz aller Tokens:
tokens <- sum(corona_tbl$Freq)
# Anzahl der Hapax Legomena: Anzahl der Types mit dem Frequenzwert 1:
hapaxes <- length(which(corona_tbl$Freq==1))
# Realisierte Produktivität:
hapaxes / tokens
corona_tbl
# Potentielle Produktivität:
types / tokens
d
d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
)
d %>% select(head, date) %>% table()
d %>% select(head, date) %>% table() %>% as_tibble()
d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
)
d2 <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
)
bubble <- gvisMotionChart(filter(d2, Freq >= 5), idvar = "head", timevar = "date")
d2 <- d %>% select(head, date) %>% table() %>% as_tibble()
d2
bubble <- gvisMotionChart(filter(d2, n >= 5), idvar = "head", timevar = "date")
d2$date <- as_date(d2$date)
bubble <- gvisMotionChart(filter(d2, n >= 5), idvar = "head", timevar = "date")
plot(bubble)
d2
filter(d2, n>=5)
plot(bubble)
d2 <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
)
d2 <- d %>% select(head, date) %>% table() %>% as_tibble()
d2 <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
)
d2 <- d %>% select(head, date) %>% table() %>% as_tibble()
nrow(filter(d2, Freq>=5))
nrow(filter(d2, n>=5))
d2 <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
)
nrow(filter(d2, Freq>=5))
d %>% select(head, date) %>% table()
d %>% select(head, date) %>% table() %>% as.data.frame
d %>% select(head, date) %>% table() %>% as.data.frame %>% filter(n>0)
d %>% select(head, date) %>% table() %>% as.data.frame %>% filter(Freq>0)
d %>% select(head, date) %>% table() %>% as.data.frame %>% filter(Freq>0) %>% nrow
d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
) %>% nroq
d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
) %>% nrow
d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
)
d2a <- d %>% select(head, date) %>% table() %>% as.data.frame %>% filter(Freq>0) %>% nrow
d2b <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
)
d2a$date <- as_date(d2a$date)
d2b$date <- as_date(d2b$date)
d2a <- d %>% select(head, date) %>% table() %>% as.data.frame %>% filter(Freq>0) %>% nrow
d2b <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
)
d2a$date <- as_date(d2a$date)
d2b$date <- as_date(d2b$date)
d2a <- d %>% select(head, date) %>% table() %>% as.data.frame %>% filter(Freq>0)
d2b <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
)
d2a$date <- as_date(d2a$date)
d2b$date <- as_date(d2b$date)
bubble <- gvisMotionChart(filter(d2a, n >= 5), idvar = "head", timevar = "date")
bubble <- gvisMotionChart(filter(d2b, n >= 5), idvar = "head", timevar = "date")
d2a
d2b
d2a
colnames(d2a)
colnames(d2b)
bubble <- gvisMotionChart(filter(d2b, n >= 5), idvar = "head", timevar = "date")
bubble <- gvisMotionChart(d2a, idvar = "head", timevar = "date")
bubble <- gvisMotionChart(d2b, idvar = "head", timevar = "date")
d2b
d2a
str(d2a)
str(d2b)
str(d2b)
str(as.data.frame(d2b))
as_tibble(d2b)
as_tibble(d2b) %>% str
d2b <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
) %>% as_tibble
?summarise
str(d2b)
d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
) %>% str
library(tidyverse)
library(googleVis)
library(lubridate)
library(collostructions)
d <- read_delim("Coronakomposita.txt", delim = "\t",
col_names = c("Freq", "word", "date"))
d
str(d)
# Fehltreffer reduzieren
d <- d[-which(sapply(1:nrow(d), function(i) nchar(d$word[i]))<=8),]
# Groß- und Kleinschreibung ignorieren
d$word <- tolower(d$word)
# Köpfe
d$head <- gsub("corona-?", "", d$word)
# Interpunktion löschen
d$head <- gsub("[[:punct:]]", "", d$head)
Wir fassen die Daten nun mit der `summarise`-Funktion aus dem dplyr-Paket (Teil des "Tidyverse") zusammen, um die Gesamtfrequenzen jedes Bestimmungsglieds zu bekommen, und ordnen die Daten absteigend nach Frequenz. Das Ganze speichern wir in einen eigene Dataframe, den wir `corona_tbl` nennen.
```{r summary}
corona_tbl <- d %>% group_by(head) %>% summarise(
Freq = sum(Freq)
) %>% arrange(desc(Freq))
# Anzahl der Types = Anzahl der Zeilen der eben genereierten Tabelle:
types <- nrow(corona_tbl)
# Anzahl der Tokens = Summe der Frequenz aller Tokens:
tokens <- sum(corona_tbl$Freq)
# Anzahl der Hapax Legomena: Anzahl der Types mit dem Frequenzwert 1:
hapaxes <- length(which(corona_tbl$Freq==1))
# Realisierte Produktivität:
hapaxes / tokens
# Potentielle Produktivität:
types / tokens
d2b <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
) %>% as_tibble
rm(d2b)
d2 <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
) %>% as_tibble
d2
str(d2)
bubble <- gvisMotionChart(d2, idvar = "head", timevar = "date")
plot(bubble)
log(e)
?log
plot(corona_tbl$Freq, type = "b", ylab = "Absolute Frequenz")
plot(log(corona_tbl$Freq), type = "b", ylab = "Logarithmierte Frequenz")
log(d2$Freq)
log(d2$Freq) %>% plot
d2$logFreq <- log(d2$Freq)
bubble <- gvisMotionChart(d2, "head", "date")
bubble <- gvisMotionChart(d2, "head", "date", sizevar = "LogFreq")
plot(bubble)
bubble <- gvisMotionChart(d2, "head", "date", sizevar = "logFreq")
plot(bubble)
bubble <- gvisMotionChart(d2, "head", "date", xvar = "logFreq", yvar = "logFreq")
plot(bubble)
plot(bubble)
set.seed(100)
d2$index <- sample(1:nrow(d2), nrow(d2))
?set.seed
bubble <- gvisMotionChart(d2, "head", "date", xvar = "index", yvar = "logFreq")
plot(bubble)
set.seed(100)
lemmas <- unique(d2$head)
set.seed(100)
spl <- tibble(
head = unique(d2$head),
sample = sample(1:length(unique(d2$head)), unique(d2$head))
)
sample(1:length(unique(d2$head)), unique(d2$head))
unique(d2$head)
length(unique(d2$head))
sample(1:(length(unique(d2$head))), length(unique(d2$head)))
spl <- tibble(
head = unique(d2$head),
sample = sample(1:(length(unique(d2$head))), length(unique(d2$head)))
)
set.seed(100)
spl <- tibble(
head = unique(d2$head),
sample = sample(1:(length(unique(d2$head))), length(unique(d2$head)))
)
left_join(d2, spl, by = "head")
d2 <- left_join(d2, spl, by = "head")
bubble <- gvisMotionChart(d2, "head", "date", xvar = "index", yvar = "logFreq")
plot(bubble)
spl
which(duplicated(spl$head))
d2
d2[which(d2$head=="krise")]
d2[which(d2$head=="krise"),]
# Dataframe mit Zufallszahl für jedes Lemma
spl <- tibble(
head = unique(d2$head),
index = sample(1:(length(unique(d2$head))), length(unique(d2$head)))
)
---
title: 'Corona-Morphologie: Einfache Produktivitätsanalysen an konkreten Beispielen'
author: "Stefan Hartmann"
date: "`r Sys.Date()`"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Morphologische Produktivität live: Ein Blick auf die Bestimmungsglieder
In diesem Abschnitt wollen wir uns nun einen anderen Weg anschauen, auf dem wir uns den Daten nähern können. Hierfür arbeiten wir mit R - falls Sie sich hier einarbeiten wollen, finden Sie online extrem viele gute Tutorials, und es gibt auch viele Einführungen in die Statistik speziell für Linguist*innen, die mit R arbeiten. Hier kann ich nicht in R einführen, versuche aber, das, was ich mache, so verständlich zu beschreiben, dass Sie zumindest das Konzept hinter dem, was ich mache, verstehen können.
Zunächst lade ich einige Zusatzpakete, die ich im Folgenden benutzen möchte. Sie enthalten Funktionen, die in R nicht standardmäßig enthalten sind. Wenn Sie die Pakete noch nicht installiert haben, müssen Sie siejedes einzelne zunächst mit `install.packages("Paketname")` installieren. Das gilt für diejenigen, die über das "Comprehensive R Architecture Network" (CRAN) verfügbar sind. Bei einem der Pakete, "collostructions", ist dies nicht der Fall, Sie finden es unter www.sfla.ch.
```{r preliminaries, message = FALSE}
library(tidyverse)
library(googleVis)
library(lubridate)
library(collostructions)
```
Zunächst lesen wir die Daten ein, werfen einen Blick auf die Struktur der Daten und schauen uns diese mit Hilfe des `str()`-Befehls genauer an.
```{r readdata}
d <- read_delim("Coronakomposita.txt", delim = "\t",
col_names = c("Freq", "word", "date"))
```
```{r head}
d
```
```{r str}
str(d)
```
Nun löschen wir alle Datenpunkte, in denen "Corona" nicht von mindestens zwei weiteren Zeichen gefolgt wird, um Fehltreffer wie *Corona-* zu tilgen. Dann konvertieren wir alle Daten in Kleinschreibung und fügen eine Spalte hinzu, die nur die Zweitglieder enthält (also alles, was auf *Corona-* folgt). Aus dieser Spalte löschen wir zusätzlich noch alle Interpunktionszeichen, um z.B. Fälle der Kompositaschreibung mit und ohne Bindestrich zu vereinheitlichen.
```{r datawrangling}
# Fehltreffer reduzieren
d <- d[-which(sapply(1:nrow(d), function(i) nchar(d$word[i]))<=8),]
# Groß- und Kleinschreibung ignorieren
d$word <- tolower(d$word)
# Köpfe
d$head <- gsub("corona-?", "", d$word)
# Interpunktion löschen
d$head <- gsub("[[:punct:]]", "", d$head)
```
Wir fassen die Daten nun mit der `summarise`-Funktion aus dem dplyr-Paket (Teil des "Tidyverse") zusammen, um die Gesamtfrequenzen jedes Bestimmungsglieds zu bekommen, und ordnen die Daten absteigend nach Frequenz. Das Ganze speichern wir in einen eigene Dataframe, den wir `corona_tbl` nennen.
```{r summary}
corona_tbl <- d %>% group_by(head) %>% summarise(
Freq = sum(Freq)
) %>% arrange(desc(Freq))
```
Mit Hilfe dieser Daten können wir nun sehr einfach auch die Kennzahlen errechnen, die wir auf der letzten Seite kennengelernt und mit Excel errechnet haben:
```{r prod}
# Anzahl der Types = Anzahl der Zeilen der eben genereierten Tabelle:
types <- nrow(corona_tbl)
# Anzahl der Tokens = Summe der Frequenz aller Tokens:
tokens <- sum(corona_tbl$Freq)
# Anzahl der Hapax Legomena: Anzahl der Types mit dem Frequenzwert 1:
hapaxes <- length(which(corona_tbl$Freq==1))
# Realisierte Produktivität:
hapaxes / tokens
```
```{r potprod}
# Potentielle Produktivität:
types / tokens
```
Wir können mit R aber noch viel mehr machen. So können wir mit Hilfe von R ein sogenanntes Motion Chart erstellen. In so einem Motion Chart könnnen wir dann die Entstehung neuer Wortbildungsprodukte quasi "live" mitverfolgen. Dafür brauchen wir aber zunächst eine Tabelle, die auch die `date`-Werte, also die Kalenderdaten, mit einschließt, die wir aus der soeben erstellten `corona_tbl`-Tabelle gelöscht haben. Wir verwenden wiede die summarise-Funktion, die wir oben bereits kennengelernt haben. Der Zusatz `as_tibble` ist hier aus technischen Gründen nötig, weil die GoogleVis-Funktion, die wir später benutzen, den entstehenden Dataframe sonst nicht als Input akzeptiert. "Tibble" ist das Default-Dataframe-Format der Tidyverse-Pakete, und der Output der summarise-Funktion ist zwar selbst ein(e?) Tibble, aber mit zusätzlichen Attributen, derer wir uns auf diese Weise entledigen.
```{r tabelle}
d2 <- d %>% group_by(head, date) %>% summarise(
Freq = sum(Freq)
) %>% as_tibble
```
Es ist in vielen Fällen sinnvoll, Frequenzen zu logarithmieren (vgl. hierzu z.B. https://de.wikipedia.org/wiki/Logarithmus). Gerade bei Frequenzdaten ist es üblich, sie zu logarithmieren, da Wortfrequenzen oft einer sehr schiefen Verteilung folgen, wie wir auch an diesen Daten sehen können:
```{r zipf}
plot(corona_tbl$Freq, type = "b", ylab = "Absolute Frequenz")
```
Einige wenige Tokens sind extremst häufig, viele sehr selten und die allermeisten Hapaxe, haben also eine Frequenz von 1. Anders sieht es aus, wenn wir die Daten logarithmieren:
```{r zipf2}
plot(log(corona_tbl$Freq), type = "b", ylab = "Logarithmierte Frequenz")
```
Die Verteilung ist nun schon deutlich weniger schief. Fügen wir deshalb unserer Tabelle, die die Frequenz jedes einzelnen Bestimmungsglied für jedes einzelne Datum erfasst, noch eine Spalte mit logarithmierter Frequenz hinzu:
```{r log}
d2$logFreq <- log(d2$Freq)
```
Nun können wir schon zur Visualisierung übergehen, da wir die relevanten Daten haben: Bestimmungsglied (head), Kalendertag (date) und (logarithmierte) Frequenz (logFreq). In unserem MotionChart wollen wir die Frequenz auf der y-Achse (also der vertikalen Achse) darstellen. Aber um die Daten im Raum anzuordnen, brauchen wir noch eine Information, wo sie sich horizontal, also auf der x-Achse, befinden sollen. Dafür fügen wir eine (bedeutunglose) Indexvariable mit randomisierten Zahlen ein. Mit Hilfe des `set.seed`-Befehls stelle ich im folgenden Code sicher, dass Sie "zufällig" genau das gleiche Sample erhalten werden wie ich.
```{r indexvar}
set.seed(100)
# Dataframe mit Zufallszahl für jedes Lemma
spl <- tibble(
head = unique(d2$head),
index = sample(1:(length(unique(d2$head))), length(unique(d2$head)))
)
# beide Dataframes verbinden
d2 <- left_join(d2, spl, by = "head")
bubble <- gvisMotionChart(d2, "head", "date", xvar = "index", yvar = "logFreq")
plot(bubble)
d2$year <- gsub("-.*", "", d2$date)
which(d2$year=="2020")
filter(d2, year == "2020")
d2 <- filter(d2, year == "2020")
bubble <- gvisMotionChart(d2, "head", "date", xvar = "index", yvar = "logFreq")
plot(bubble)
?gvisMotionChart
bubble <- gvisMotionChart(d2, "head", "date", xvar = "index", yvar = "logFreq", sizevar = "logFreq", colvar = "")
bubble <- gvisMotionChart(d2, "head", "date", xvar = "index", yvar = "logFreq", sizevar = "logFreq", colorvar = "")
plot(bubble)
# einlesen
nouns <- read_delim("allnouns_dwds21.txt",
delim = "\t", quote="",
col_names = c("Freq_dwds21", "word"))
# alle in Kleinschreibung
nouns$word <- tolower(nouns$word)
# neu auszählen (um groß- und kleingeschriebene Varianten zu vereinen)
nouns <- nouns %>% group_by(word) %>% summarise(
Freq_dwds21 = sum(Freq_dwds21)
)
corona_tbl <- left_join(corona_tbl, nouns, by = c("head" = "word"))
corona_tbl <- replace_na(corona_tbl, list(Freq_dwds21 = 0))
corona_coll <- collex.dist(as.data.frame(corona_tbl))
head(corona_coll)
head(corona_coll, 10)
tail(corona_coll)
select(corona_coll, -SHARED)
select(corona_coll, -SHARED) %>% head(10)
select(corona_coll, -SHARED) %>% tail(10)
left_join(d2, corona_coll, by = c("head" = "COLLEX"))
d2 <- left_join(d2, corona_coll, by = c("head" = "COLLEX"))
corona_coll$COLL.STR.LOGL
log(corona_coll$COLL.STR.LOGL)
log(corona_coll$COLL.STR.LOGL) %>% plot
which(is.na(log(corona_coll$COLL.STR.LOGL)))
log(corona_coll$COLL.STR.LOGL)
corona_coll$Log_assoc <- log(corona_coll$COLL.STR.LOGL)
corona_coll$ASSOC %>% unique
corona_coll$Log_assoc2 <- ifelse(corona_coll$ASSOC=="Freq_dwds21", -corona_coll$Log_assoc, corona_coll$Log_assoc)
d2 <- left_join(d2, corona_coll, by = c("head" = "COLLEX"))
d2
bubble2 <- gvisMotionChart(d2, idvar = "head", timevar = "date",
xvar = "Log_assoc2", yvar = "logFreq",
sizevar="logFreq")
plot(bubble2)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook")
?read_delim
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook")
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook")
# einlesen
library(tidyverse)
nouns <- read_delim("allnouns_dwds21.txt",
delim = "\t", quote="",
col_names = c("Freq_dwds21", "word"))
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook")
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook")
?render_book
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
